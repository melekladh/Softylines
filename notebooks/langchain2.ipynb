{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f56429e",
   "metadata": {},
   "source": [
    "chatmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba012c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 29 key-value pairs and 292 tensors from ../models/dolphin.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Dolphin 3.0 Llama 3.1 8B\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Cognitivecomputations\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Dolphin-3.0-Llama-3.1\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   7:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   8:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   9:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  10:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  11:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  13:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  14:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  15:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  16:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  17:                           llama.vocab_size u32              = 128258\n",
      "llama_model_loader: - kv  18:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  19:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  20:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.tokens arr[str,128258]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,128258]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.eos_token_id u32              = 128256\n",
      "llama_model_loader: - kv  26:            tokenizer.ggml.padding_token_id u32              = 128001\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n",
      "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   66 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q8_0\n",
      "print_info: file size   = 7.95 GiB (8.50 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 2\n",
      "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "load: control token: 128257 '<|im_start|>' is not marked as EOG\n",
      "load: printing all EOG tokens:\n",
      "load:   - 128001 ('<|end_of_text|>')\n",
      "load:   - 128008 ('<|eom_id|>')\n",
      "load:   - 128009 ('<|eot_id|>')\n",
      "load:   - 128256 ('<|im_end|>')\n",
      "load: special tokens cache size = 258\n",
      "load: token to piece cache size = 0.7999 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 500000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 8B\n",
      "print_info: model params     = 8.03 B\n",
      "print_info: general.name     = Dolphin 3.0 Llama 3.1 8B\n",
      "print_info: vocab type       = BPE\n",
      "print_info: n_vocab          = 128258\n",
      "print_info: n_merges         = 280147\n",
      "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
      "print_info: EOS token        = 128256 '<|im_end|>'\n",
      "print_info: EOT token        = 128256 '<|im_end|>'\n",
      "print_info: EOM token        = 128008 '<|eom_id|>'\n",
      "print_info: PAD token        = 128001 '<|end_of_text|>'\n",
      "print_info: LF token         = 198 'Ċ'\n",
      "print_info: EOG token        = 128001 '<|end_of_text|>'\n",
      "print_info: EOG token        = 128008 '<|eom_id|>'\n",
      "print_info: EOG token        = 128009 '<|eot_id|>'\n",
      "print_info: EOG token        = 128256 '<|im_end|>'\n",
      "print_info: max token length = 256\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q8_0) (and 322 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  8137.66 MiB\n",
      ".........................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 64\n",
      "llama_context: n_ubatch      = 8\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 10000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.49 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified: layer  28: dev = CPU\n",
      "llama_kv_cache_unified: layer  29: dev = CPU\n",
      "llama_kv_cache_unified: layer  30: dev = CPU\n",
      "llama_kv_cache_unified: layer  31: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   256.00 MiB\n",
      "llama_kv_cache_unified: size =  256.00 MiB (  2048 cells,  32 layers,  1/1 seqs), K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 2336\n",
      "llama_context: worst-case: n_tokens = 8, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    8, n_seqs =  1, n_outputs =    8\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    8, n_seqs =  1, n_outputs =    8\n",
      "llama_context:        CPU compute buffer size =     4.16 MiB\n",
      "llama_context: graph nodes  = 1126\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.name': 'Dolphin 3.0 Llama 3.1 8B', 'general.architecture': 'llama', 'general.type': 'model', 'general.organization': 'Cognitivecomputations', 'llama.context_length': '131072', 'llama.block_count': '32', 'general.basename': 'Dolphin-3.0-Llama-3.1', 'general.size_label': '8B', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '128256', 'general.file_type': '7', 'llama.attention.head_count_kv': '8', 'llama.rope.freq_base': '500000.000000', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.attention.key_length': '128', 'llama.attention.value_length': '128', 'llama.vocab_size': '128258', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.padding_token_id': '128001', 'tokenizer.chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"../models/dolphin.gguf\",\n",
    "    n_ctx=2048,\n",
    "    temperature=0,\n",
    "    max_tokens=2000,\n",
    "    top_p=1,  \n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,  \n",
    "  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b3ca2",
   "metadata": {},
   "source": [
    "emebdding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3627a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taki Academy\\taki\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"Omartificial-Intelligence-Space/GATE-AraBert-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77649570",
   "metadata": {},
   "source": [
    "vector store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9964f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a2463",
   "metadata": {},
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269be123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1}, page_content='كان عدد المشتركين في شبكة الاتصالات في الولايات المتحدة الأمريكية 646 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في الهاتف القار 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل البصرية والأقمار صناعية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=\"../data/json/process_data.json\",\n",
    "    jq_schema=\".summary\",\n",
    "    text_content=False,\n",
    ")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d85315",
   "metadata": {},
   "source": [
    "splitting documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a3d5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 5 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,  \n",
    "    chunk_overlap=50, \n",
    "    add_start_index=True,  \n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a971a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 0}, page_content='كان عدد المشتركين في شبكة الاتصالات في الولايات المتحدة الأمريكية 646 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في الهاتف القار 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 152}, page_content='ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 302}, page_content='كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 448}, page_content='المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل البصرية والأقمار صناعية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 598}, page_content='في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2637c",
   "metadata": {},
   "source": [
    "Storing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade8984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taki Academy\\taki\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a7f9aa87-c1c8-47d7-acbb-a2981305da14',\n",
       " '9768496d-8c84-42d5-b81e-2778cf5f0238',\n",
       " '7240b661-9fcc-4a19-a87f-ccfda4dcc38f',\n",
       " 'f2b5d361-764e-41e6-b49e-4fe1d3c555b6',\n",
       " '2691318f-f31a-4db2-8ef2-b856ed33112b']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "(document_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f22e1",
   "metadata": {},
   "source": [
    "2. Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a22b277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='a7f9aa87-c1c8-47d7-acbb-a2981305da14', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 0}, page_content='كان عدد المشتركين في شبكة الاتصالات في الولايات المتحدة الأمريكية 646 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في الهاتف القار 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل'),\n",
       " Document(id='f2b5d361-764e-41e6-b49e-4fe1d3c555b6', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 448}, page_content='المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل البصرية والأقمار صناعية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة'),\n",
       " Document(id='9768496d-8c84-42d5-b81e-2778cf5f0238', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 152}, page_content='ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك'),\n",
       " Document(id='7240b661-9fcc-4a19-a87f-ccfda4dcc38f', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 302}, page_content='كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "  \"عدد المشتركين في شبكة الاتصالات \")\n",
    "(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "099f67fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='a7f9aa87-c1c8-47d7-acbb-a2981305da14', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 0}, page_content='كان عدد المشتركين في شبكة الاتصالات في الولايات المتحدة الأمريكية 646 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في الهاتف القار 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل'),\n",
       " Document(id='9768496d-8c84-42d5-b81e-2778cf5f0238', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 152}, page_content='ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك'),\n",
       " Document(id='7240b661-9fcc-4a19-a87f-ccfda4dcc38f', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 302}, page_content='كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000'),\n",
       " Document(id='f2b5d361-764e-41e6-b49e-4fe1d3c555b6', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 448}, page_content='المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل البصرية والأقمار صناعية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "  \"عدد المشتركين في الهاتف القار\")\n",
    "\n",
    "(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f301569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='f2b5d361-764e-41e6-b49e-4fe1d3c555b6', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 448}, page_content='المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل البصرية والأقمار صناعية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة'),\n",
       " Document(id='7240b661-9fcc-4a19-a87f-ccfda4dcc38f', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 302}, page_content='كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000'),\n",
       " Document(id='9768496d-8c84-42d5-b81e-2778cf5f0238', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 152}, page_content='ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك'),\n",
       " Document(id='a7f9aa87-c1c8-47d7-acbb-a2981305da14', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 0}, page_content='كان عدد المشتركين في شبكة الاتصالات في الولايات المتحدة الأمريكية 646 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في الهاتف القار 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "  \"عدد المشتركين في التلفزة بالكابل\")\n",
    "(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc7c5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taki Academy\\taki\\.venv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "c:\\Users\\Taki Academy\\taki\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " كان عدد المشتركين في شبكة الاتصالات 646 مشترك لكل 1,000 ساكن."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =   14791.50 ms\n",
      "llama_perf_context_print: prompt eval time =   14791.39 ms /   196 tokens (   75.47 ms per token,    13.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5372.44 ms /    23 runs   (  233.58 ms per token,     4.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   20208.58 ms /   219 tokens\n",
      "llama_perf_context_print:    graphs reused =         40\n"
     ]
    }
   ],
   "source": [
    "question =   \"عدد المشتركين في شبكة الاتصالات\" \n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question,k=2)\n",
    "\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "prompt_value = prompt.invoke({\"question\": question, \"context\": docs_content })\n",
    "answer = llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e6d3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taki Academy\\taki\\.venv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "c:\\Users\\Taki Academy\\taki\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Llama.generate: 60 prefix-match hit, remaining 149 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='a7f9aa87-c1c8-47d7-acbb-a2981305da14', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 0}, page_content='كان عدد المشتركين في شبكة الاتصالات في الولايات المتحدة الأمريكية 646 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في الهاتف القار 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل'), Document(id='9768496d-8c84-42d5-b81e-2778cf5f0238', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 152}, page_content='ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك')]\n",
      " عدد المشتركين في الهاتف القار 488 مشترك لكل 1,000 ساكن"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =   14791.50 ms\n",
      "llama_perf_context_print: prompt eval time =    9939.09 ms /   149 tokens (   66.71 ms per token,    14.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4834.57 ms /    20 runs   (  241.73 ms per token,     4.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   14813.22 ms /   169 tokens\n",
      "llama_perf_context_print:    graphs reused =         31\n"
     ]
    }
   ],
   "source": [
    "question =  \"عدد المشتركين في الهاتف القار\"\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question,k=2)\n",
    "print(retrieved_docs)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "prompt_value = prompt.invoke({\"question\": question, \"context\": docs_content })\n",
    "answer = llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "938019cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taki Academy\\taki\\.venv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "c:\\Users\\Taki Academy\\taki\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Llama.generate: 60 prefix-match hit, remaining 144 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='f2b5d361-764e-41e6-b49e-4fe1d3c555b6', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 448}, page_content='المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل البصرية والأقمار صناعية في الولايات متحدة الأمريكية في الولايات متحدة الأمريكية في الولايات متحدة'), Document(id='7240b661-9fcc-4a19-a87f-ccfda4dcc38f', metadata={'source': 'C:\\\\Users\\\\Taki Academy\\\\taki\\\\data\\\\json\\\\process_data.json', 'seq_num': 1, 'start_index': 302}, page_content='كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن، بينما كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000')]\n",
      " كان عدد المشتركين في التلفزة بالكابل 488 مشترك لكل 1,000 ساكن."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =   14791.50 ms\n",
      "llama_perf_context_print: prompt eval time =   10106.62 ms /   144 tokens (   70.18 ms per token,    14.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5902.32 ms /    24 runs   (  245.93 ms per token,     4.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   16059.31 ms /   168 tokens\n",
      "llama_perf_context_print:    graphs reused =         35\n"
     ]
    }
   ],
   "source": [
    "question =  \"عدد المشتركين في التلفزة بالكابل\"\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question,k=2)\n",
    "print (retrieved_docs)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "prompt_value = prompt.invoke({\"question\": question, \"context\": docs_content })\n",
    "answer = llm.invoke(prompt_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
