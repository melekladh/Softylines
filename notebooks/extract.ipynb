{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a430f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2317d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract (path):\n",
    "    import torch\n",
    "    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "    from datasets import load_dataset\n",
    "\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "    model_id = \"openai/whisper-small\"\n",
    "\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device,\n",
    "        return_timestamps=True\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    result = pipe(\"data/audio11.mp4\")\n",
    "    return result[\"text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d7ae7",
   "metadata": {},
   "source": [
    "stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51ddb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=\"نواصل وحديثنا عن دور شبكات النقل والاتصال في تنظيم المجال في الولايات المتحدة الأمريكية إذن لدينا وثائق هي موجودة عندكم في الكتاب المدرسي حبيت أن أضعها لكم كما هي ولكن أسوقها باحتراز على أساس أن المعطيات فيها ولا تقدمها إذن عدد المشتركين في شبكة الاتصالات في الولايات المتحدة الأمريكية سنة 2002 أكيد الأرقام الآن زادت أكيد عدد المشتركين في الهاتف القارس 646 مشترك لكل 1000 ساكن ونتصورها معناها المعدل يعني المعدل مش عدد تراجع أمامها يعني انتشار وكثرة استعمال الهاتف الجوال معدل المشتركين بالهاتف الجوال 488 مشترك لكل 1000 سكن ونتصورها فاتت حتى 700 أو 800 مشترك عدد المشتركين في التلفزة بالكابل يعني مفهميش تلفزة بالكابل يعني من غير بارابول من غير هوائي فضائي أو أرضي الأرضي هذيك معاش نحكيه عليه جملة إذن 30 مليون في بلاد هي ولد فيها تقوى 340 مليون فالعكد على قل مع تل عدد تثرب في ثلاثة الآن معدل ثم أيضاً ثم انخيرات في التلفزيون بالكابل أو عن تاريخ الانترنت اشتراكات في الانترنت كما عنا في تونس لبي تي في معدل مشتركين في شبكة الانترنت 551 منخرط لكل 1000 ساكن وهذا يزيد أيضاً نفس الشيء نتخيله لا يقل عن 700 أو 800 الوثيقة الموالية وسائل الاتصال الحديثة بالولايات المتحدة الأمريكية إذن أرست الولايات المتحدة الأمريكية شبكة اتصالات حديثة من أفخم الشبكات في العالم لنقل المعلومات ومن أحدثها الهاتف والفاكس والتلفزة والإنترنت الفاكس أيضا هذا جهاز نوعا ما تجاوزه الزمن وقد أحدثت أو أحدثت ثورة في مجال الاتصالات وقلصت المسافات وحررت الأنشطة فأدت إلى إعادة انتشارها من كتاب جغرافية العالم المعاصر إذن ثانيا عربي دور شبكات الاتصال في تنظيم المجال الأمريكي تتميز شبكات الاتصال في الولايات المتحدة الأمريكية بعراقتها حيث تعتبر أقدم الشبكات في العالم وبكثافتها حيث تحتوي أكبر معدلات الاشتراك في مختلف الشبكات حيث يبلغ معدل المشتركين بالهاتف القار 646 مشترك لكل 1000 ساكن ومعدل مشتركين في شبكة الانترنت 551 منخرط لكل 1000 سكن وهي مستويات قياسية مقارنة ببقية البلدان المتقدمة تحتكم الولايات المتحدة الأمريكية على شبكة اتصالات متطورة جدا مثل التليبور وشبكات الألياف البصرية والأقمار الصناعية مكنت من تسهيل الاتصالات والربط بين مختلف مكونات المجال الأمريكي كما تم إدماج مختلف مجالات العالم ضمن الشبكة العنكبوتية التي يوجد مركزها في الولايات المتحدة الأمريكية\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55e492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\taki academy\\taki\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\taki academy\\taki\\.venv\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\taki academy\\taki\\.venv\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\taki academy\\taki\\.venv\\lib\\site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\taki academy\\taki\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\taki academy\\taki\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import nltk\n",
    "# from nltk.stem.isri import ISRIStemmer\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "# st = ISRIStemmer()\n",
    "\n",
    "# w= sample\n",
    "\n",
    "# for a in word_tokenize(w):\n",
    "\n",
    "#     print(st.stem(a)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f1f953",
   "metadata": {},
   "source": [
    "llematization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b41849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.isri import ISRIStemmer\n",
    "# st = ISRIStemmer()\n",
    "# print st.suf32(u'اعلاميون')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd878e23",
   "metadata": {},
   "source": [
    "remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5330cb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Arabic-Stopwords\n",
      "  Downloading Arabic_Stopwords-0.4.3-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting pyarabic>=0.6.2 (from Arabic-Stopwords)\n",
      "  Downloading PyArabic-0.6.15-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\taki academy\\taki\\.venv\\lib\\site-packages (from pyarabic>=0.6.2->Arabic-Stopwords) (1.17.0)\n",
      "Downloading Arabic_Stopwords-0.4.3-py3-none-any.whl (360 kB)\n",
      "Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: pyarabic, Arabic-Stopwords\n",
      "\n",
      "   ---------------------------------------- 0/2 [pyarabic]\n",
      "   -------------------- ------------------- 1/2 [Arabic-Stopwords]\n",
      "   -------------------- ------------------- 1/2 [Arabic-Stopwords]\n",
      "   -------------------- ------------------- 1/2 [Arabic-Stopwords]\n",
      "   ---------------------------------------- 2/2 [Arabic-Stopwords]\n",
      "\n",
      "Successfully installed Arabic-Stopwords-0.4.3 pyarabic-0.6.15\n"
     ]
    }
   ],
   "source": [
    "!pip install Arabic-Stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stemmer ():\n",
    "    \n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import nltk\n",
    "    from nltk.stem.isri import ISRIStemmer\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('punkt_tab')\n",
    "    import arabicstopwords.arabicstopwords as stp\n",
    "    st = ISRIStemmer()\n",
    "    text = sample\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if not stp.is_stop(word)]\n",
    "    filtered_text = \" \".join(filtered_tokens)\n",
    "    result = \"\"\n",
    "\n",
    "    for a in word_tokenize(filtered_text):\n",
    "        stemmed_word = st.stem(a)\n",
    "        result += stemmed_word + \" \"\n",
    "        return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acca5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'نصل حدث دور شبك نقل تصل نظم جال ولي تحد امر وثق وجد كتب درس حبت اضع اسق حرز اسس عطي قدم عدد شرك شبك تصل ولي تحد امر سنة 2002 اكد رقم زدت اكد عدد شرك هتف قرس 646 شرك 1000 سكن تصر عنا عدل يعن عدل مش عدد رجع يعن نشر كثر عمل هتف جول عدل شرك هتف جول 488 شرك 1000 سكن تصر فتت 700 800 شرك عدد شرك لفز كبل يعن مفهميش لفز كبل يعن ربل هئي فضي ارض ارض هذك عاش نحك جمل 30 ملي بلد ولد تقى 340 ملي عكد قل تل عدد ثرب ثلث عدل ايض خير لفز كبل ارخ نرن شرك نرن عنا ونس لبي عدل شرك شبك نرن 551 خرط 1000 سكن يزد ايض شيء تخل يقل 700 800 وثق ولي وسل تصل حدث ولي تحد امر ارس ولي تحد امر شبك تصل حدث فخم شبك علم نقل علم حدث هتف فكس لفز نرن فكس جهز نوع جوز زمن حدث حدث ثور جال تصل قلص ساف حرر نشط فأد عدة نشر كتب جغراف علم عصر ثان عرب دور شبك تصل نظم جال امر تمز شبك تصل ولي تحد امر عرق عبر قدم شبك علم كثف حوي كبر عدل شرك خلف شبك بلغ عدل شرك هتف قار 646 شرك 1000 سكن عدل شرك شبك نرن 551 خرط 1000 سكن ستي قيس قرن ببق بلد تقدم ولي تحد امر شبك تصل تطر يبر وشب ليف بصر قمر صنع كنت سهل تصل ربط خلف كون جال امر تم دمج خلف جال علم شبك عنكبوتية وجد ركز ولي تحد امر '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc11231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
